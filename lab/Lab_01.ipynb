{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "<table align=\"left\" style=\"border-style: hidden\" class=\"table\"> <tr><td class=\"col-md-2\"><img style=\"float\" src=\"http://prob140.org/assets/icon256.png\" alt=\"Prob140 Logo\" style=\"width: 120px;\"/></td><td><div align=\"left\"><h3 style=\"margin-top: 0;\">Probability for Data Science</h3><h4 style=\"margin-top: 20px;\">UC Berkeley, Spring 2022</h4><p>Ani Adhikari</p>CC BY-NC-SA 4.0</div></td></tr></table><!-- not in pdf -->\n",
    "\n",
    "This content is protected and may not be shared, uploaded, or distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "# SETUP\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "from prob140 import *\n",
    "\n",
    "# These lines do some fancy plotting magic\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Useful for probability calculations\n",
    "from scipy import stats\n",
    "# add following line of code\n",
    "from scipy import special\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Instructions\n",
    "Your labs have two components: a written portion and a portion that also involves code. Written work should be completed on paper, and coding questions should be done in the notebook. You are welcome to LaTeX your answers to the written portions, but staff will not be able to assist you with LaTeX related issues. It is your responsibility to ensure that both components of the lab are submitted completely and properly to Gradescope. Refer to the bottom of the notebook for submission instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "# Lab 1: Total Variation #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Lab Resources\n",
    "\n",
    "* [`prob 140` Library Documentation](http://prob140.org/prob140/)\n",
    "* [`datascience` Library Documentation](http://data8.org/datascience/)\n",
    "* [Prob 140 Code Reference Sheet](http://prob140.org/assets/prob140_code_reference.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "In Data 8, you measured the difference between two categorical distributions by calculating the total variation distance (TVD) between them. The bigger the distance, the less similar the two distributions are. But in Data 8, we didn't discuss some obvious questions about the TVD, such as:\n",
    "\n",
    "- How big could the TVD between two distributions be? Could it be arbitrarily large, like the distance between two points on the number line?\n",
    "- Is there any way to interpret the numerical value of the TVD? For example, if we know that the TVD between two distributions is 0.02, what does that tell us?\n",
    "\n",
    "In this lab, you will start by interpreting the total variation distance in terms of probabilities. You will then use the TVD to measure the difference between two probability distributions on the non-negative integers. In Data 8 terms, you can think of each non-negative integer as a \"category\".\n",
    "\n",
    "**The main point of the lab is that the total variation distance will give you a precise way to quantify how well one probability distribution approximates another.**\n",
    "\n",
    "Our focus will be on *Poisson* distributions, which are often used as approximations to distributions of counts of rare events. In particular, the Poisson $(1)$ distribution approximates the distributions of some random counts that have $0$ and $1$ as their most likely values.\n",
    "\n",
    "A random variable $X$ has the Poisson $(1)$ distribution if\n",
    "\n",
    "$$\n",
    "P(X = k) ~ = ~ e^{-1} \\frac{1}{k!}, ~~~ k \\ge 0\n",
    "$$\n",
    "\n",
    "This is a probability distribution on infinitely many possible values. We will need that infinite support if we are going to approximate distributions on the values $0, 1, 2, \\ldots, n$ for arbitrarily large $n$.\n",
    "\n",
    "In class we are studying two situations in which probabilities approach those in a Poisson distribution. One is counting the number of matches in the matching problem with $n$ letters, when $n$ is large. The other is counting the number of successes in $n$ i.i.d. Bernoulli $(p)$ trials, for large $n$ and small $p$.\n",
    "\n",
    "In this lab you will look at the entire distribution of the number of matches, and also the binomial $(n, 1/n)$ distribution. You will compare them with their Poisson $(1)$ approximations, both visually and also by the TVD. \n",
    "\n",
    "In doing so, you will find an upper bound for the amount of error you can make when you use the approximations to calculate probabilities.\n",
    "\n",
    "What you will learn:\n",
    "- The definition of total variation distance and its interpretation in terms of the amount of error in approximating probabilities\n",
    "- For large $n$, properties of the TVD between the distribution of the number of matches and the Poisson $(1)$ distribution\n",
    "- For large $n$, properties of the TVD between the binomial $(n, 1/n)$ and Poisson $(1)$ distributions\n",
    "- A generalization of the binomial distribution, and a simple upper bound on a related TVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "# Part A of the lab starts here # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Identify Your Lab Partner ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "This is a multiple choice question. Please select **ONE** of following options that best describes how you complete **Part A** of this lab.\n",
    "\n",
    "* I am doing Part A of this lab by myself and I don't have a partner.\n",
    "* My partner for Part A of this lab is [NAME] with email [berkeley.edu email address]. [NAME] will submit for both of us on Gradescope.\n",
    "\n",
    "Please copy and paste **ONE** of above statements and fill in blanks if needed. If you work with a partner, make sure only one of you submit on Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 1: Total Variation Distance ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Suppose you have two probability distributions on the same set of possible values $x_1, x_2, \\ldots , x_n$. Let the two distributions be $b_1, b_2, \\ldots, b_n$ and $g_1, g_2, \\ldots, g_n$, where for each $i$ the $b$-distribution assigns probability $b_i$ to the value $x_i$ and the $g$-distribution assigns probability $g_i$.\n",
    "\n",
    "The *total variation distance* between the two distributions is defined by\n",
    "\n",
    "$$\n",
    "tvd(b, g) = \n",
    "\\frac{1}{2} \\sum_{i=1}^n |b_i - g_i| \n",
    "$$\n",
    "\n",
    "The choice of notation comes from the blue and gold colors you will see in overlaid histograms below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 1a) [CODE] Computing TVD ###\n",
    "We will use the term *probability array* to mean an array of non-negative numbers that sum to 1. \n",
    "\n",
    "Define a function `tvd` that takes two probability arrays of the same size as arguments and returns the total variation distance between them. You should just assume that both of the input arrays will be probability distributions on the same set of possible values. You don't have to include code to check that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "def tvd(b, g):\n",
    "    return 1/2 * sum(abs(b - g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "When the two arrays are $b = [0.4, 0.3, 0.2, 0.1]$ and $g = [0.25, 0.35, 0.25, 0.15]$, the histograms look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = make_array(0.4, 0.3, 0.2, 0.1)\n",
    "g = make_array(0.25, 0.35, 0.25, 0.15)\n",
    "\n",
    "k = np.arange(4)\n",
    "\n",
    "blue_dist = Table().values(k).probabilities(b)\n",
    "gold_dist = Table().values(k).probabilities(g)\n",
    "\n",
    "Plots('Distribution 1', blue_dist, 'Distribution 2', gold_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Calculate the TVD by mental math. Then run the cell below to confirm that your function `tvd` is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvd(b, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "The total variation distance between the two distributions is the total amount by which the areas of the blue bars exceed those of the corresponding gold bars. That's exactly equal to the total amount by which the gold bars exceed the blue.\n",
    "\n",
    "This is almost apparent from the definition of total variation distance, and you will prove it later in this lab. Just assume it for now as you did in Data 8. It is an intuitively reasonable measure of the difference between the two distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 1b) Another Way of Interpreting TVD ###\n",
    "\n",
    "**This part will be done in section on Wednesday; don't include it in your Gradescope submission.**\n",
    "\n",
    "Thus far, our interpretation of total variation distance has been essentially geometric: the amount by which the blue bars exceed the gold. There is an equivalent interpretation in terms of probabilities that makes it easier to understand what the numerical value of the distance is telling us.\n",
    "\n",
    "Suppose you have a finite set of possible values, and a choice of two probability distributions to use for finding probabilities. For example, the choices might be the exact distribution of a random variable and an approximate distribution. \n",
    "\n",
    "**The total variation distance between the two distributions is the biggest difference you can possibly get if you compute the probability of an event using each of the two distributions.**\n",
    "\n",
    "Formally, if $S$ is the space of all possible values, then the total variation distance between the blue and gold distributions is equal to\n",
    "\n",
    "$$\n",
    "\\max\\{ \\big{\\lvert} P_{blue}(A) - P_{gold}(A) \\big{\\rvert} : A \\subseteq S\\}\n",
    "$$\n",
    "\n",
    "This can be shown in a few straightforward steps and you will do that at the end of this lab. For now, confirm that it is true for the distributions in **1a**, in the following steps.\n",
    "\n",
    "- Figure out how many events can be created out of the outcomes $\\{0, 1, 2, 3\\}$.\n",
    "- List all the events.\n",
    "- For each event, compute the absolute difference between the blue and gold probabilities of the event. Your goal is to find the biggest possible absolute difference, so you might not even need to compute each one.\n",
    "- See which event or events correspond to the biggest absolute difference, and compare the value of that absolute difference with the TVD that you computed in **1a**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 2: Fixed Points of a Random Permutation ##\n",
    "\n",
    "Let $M_n$ be the number of fixed points in a random permutation of the values $1, 2, 3, \\ldots, n$. You can think of $M_n$ as the number of matches when $n$ letters labeled $1$ through $n$ are permuted randomly into $n$ envelopes labeled $1$ through $n$.\n",
    "\n",
    "In class, we found the [distribution](http://prob140.org/textbook/content/Chapter_05/03_The_Matching_Problem.html#k-matches) of $M_n$.\n",
    "\n",
    "We also found the following approximation for large $n$: \n",
    "\n",
    "$$\n",
    "P(M_n = k) ~ \\approx ~ \\frac{e^{-1}}{k!}\n",
    "$$ \n",
    "\n",
    "These are the terms in the Poisson $(1)$ distribution.\n",
    "\n",
    "In this part of the lab you will compare the distribution of $M_n$ with its Poisson $(1)$ approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2a) [CODE] Computing $P(M_n = k)$ ###\n",
    "Complete the definition of the function `prob_matches` that takes $k$ and $n$ as its arguments and returns $P(M_n = k)$. Use as many lines of code as you need. \n",
    "\n",
    "Make sure you compute the [exact distribution](http://prob140.org/textbook/content/Chapter_05/03_The_Matching_Problem.html#k-matches) of $M_n$, not its Poisson approximation. To do this, use array operations. The `special` module of SciPy has been imported and contains a useful `factorial` method: \n",
    "\n",
    "`special.factorial(integer_array)` evaluates to an array consisting of the factorials of all the integers in `integer_array`.\n",
    "\n",
    "Be careful about signs. Follow the lead of the code provided, and tackle all the positive terms separately from all the negative terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "def prob_matches(k, n):\n",
    "    x_even = np.arange(0, n - k + 1, 2)\n",
    "    x_odd = np.arange(1, n - k + 1, 2)\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "To confirm that your function is working correctly, think about what $P(M_n = n-1)$ should be, and then run the cell below to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "prob_matches(99, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Use the formula for $P(M_n = k)$ to explain why $P(M_n = 0)$ is very close to $P(M_n = 1)$ when $n$ is large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Now run the cell below and confirm that your function is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "prob_matches(0, 100), prob_matches(1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2b) [CODE] The Bulk of the Distribution ###\n",
    "Use `prob_matches` to define a function `match_dist` that takes $n$ as its argument and returns an array consisting of the probabilities $P(M_n = k)$ for $0 \\le k \\le n$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "def match_dist(...):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "The expression `match_dist(100)[0:11]` evaluates to an array consisting of the elements 0 through 10 of the array `match_dist(100)`. \n",
    "\n",
    "Explain what the output of the cell below tells you about the distribution of $M_n$. As with most questions about random variables, start by thinking about the possible values of $M_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "sum(match_dist(100)[0:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2c) [CODE] Visualization ###\n",
    "Plot the distribution of $M_{100}$, the number of matches in the matching problem with 100 letters. Use `Plot(dist)` where `dist` is a distribution object created by either:\n",
    "\n",
    "`Table().values(array_of_values).probabilities(array_of_probabilities)`\n",
    "\n",
    "or\n",
    "\n",
    "`Table().values(array_of_values).probability_function(name_of_function)` where `name_of_function` takes a possible value as its argument and returns the probability of that value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "k = np.arange(11)\n",
    "\n",
    "...\n",
    "\n",
    "matches_100 = Table().values(k)...\n",
    "Plot(matches_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 3: Poisson Approximation to the Matching Distribution ##\n",
    "\n",
    "Recall from the introduction to the lab that $X$ has the Poisson distribution with parameter 1 if \n",
    "\n",
    "$$\n",
    "P(X = k) ~ = ~ e^{-1} \\frac{1}{k!}, ~~~ k \\ge 0\n",
    "$$\n",
    "\n",
    "The `stats` module of SciPy can be used to calculate the probabilities in this distribution. If `values` is an array of non-negative integers, then\n",
    "\n",
    "`stats.poisson.pmf(values, 1)`\n",
    "\n",
    "evaluates to an array of probabilities of the entries in `values`, determined by the Poisson $(1)$ formula above.\n",
    "\n",
    "The acronym `pmf` stands for \"probability mass function\". It is common for probabilists to think of the probabilities in the distribution of a discrete random variable as masses attached to the random variable's possible values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 3a) [CODE] The Poisson $(1)$ Distribution ###\n",
    "Draw a histogram of the Poisson $(1)$ distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "k = np.arange(11)        # selected possible values\n",
    "poisson_1_probs = ...    # array of corresponding Poisson (1) probabilities\n",
    "poisson_1_dist = ...\n",
    "Plot(poisson_1_dist)\n",
    "plt.title('Poisson (1) Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Notice:\n",
    "\n",
    "- The distribution has two modes, at 0 and 1. In exercises you will see why.\n",
    "- Though there are infinitely many possible values, the set of *probable* values is very small â€” there is hardly any probability visible beyond the value 4.\n",
    "- The distribution is extremely similar to the distribution of the number of matches in **2c**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 3b) [CODE] TVD Between the Matching Distribution and its Poisson Approximation ###\n",
    "Use the `stats` module and functions you have already defined in this lab to define a new function `matches_Poisson_tvd` that takes $n$ as its argument and returns the total variation distance between the distribution of the number of matches $M_n$ and the Poisson $(1)$ distribution.\n",
    "\n",
    "Though the Poisson distribution has infinite support, you have seen that almost all of the probability is concentrated on just a few small values. So it's fine to compute the Poisson $(1)$ probabilities only for $0, 1, 2, \\ldots, n$, the possible numbers of matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "def matches_Poisson_tvd(n):\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "To see if the value that your function is returning make sense, start by looking at the distribution of $M_5$, the number of matches if you just have 5 letters. Make sure you understand why there is a gap in the probability histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "matches_5 = Table().values(np.arange(6)).probabilities(match_dist(5))\n",
    "Plot(matches_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Which do you think should be larger: `matches_Poisson_tvd(5)` or `matches_Poisson_tvd(100)`? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Run the cell below to see that your function behaves consistently with your answer above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "matches_Poisson_tvd(5), matches_Poisson_tvd(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 3d) [CODE] Error in the Approximation ###\n",
    "Let $a$ and $b$ be two integers with $0 \\le a < b \\le 100$. Suppose you approximate $P(a \\le M_{100} \\le b)$ by $\\sum_{k=a}^b e^{-1}\\frac{1}{k!}$. What is the largest possible error you could make?\n",
    "\n",
    "**Note:** Your answer should be a number that works as an upper bound no matter which $a$ and $b$ are chosen according to the description above. If you are not sure how to proceed, re-read the introduction to the lab and think about **Part 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "The more letters you have, the better the approximation will be. To visualize this, extend `tvd_table` below with a column labeled `Matches (n)` that contains the total variation distance between the exact distribution of the number of matches and its Poisson $(1)$ approximation. In each row, the number of letters $n$ is given by the entry in Column 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "tvd_table = Table().with_column('n', np.arange(5, 101))\n",
    "\n",
    "matches_tvds = tvd_table...\n",
    "\n",
    "tvd_table = tvd_table...\n",
    "\n",
    "tvd_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Use the `Table` method `plot` to draw a line plot of the TVDs as a function of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "...\n",
    "plt.title('TVD between Binomial (n, 1/n) and Poisson (1)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Note how sharply the graph falls. For $n \\ge 10$ or so, there is almost no error at all in using the Poisson $(1)$ distribution to approximate the distribution of $M_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "# Part A of the lab ends here, and is due by 11:59 pm Monday January 31 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "# Part B of the lab starts here #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Identify your lab partner ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "This is a multiple choice question. Please select **ONE** of following options that best describes how you complete **Part B** of this lab.\n",
    "\n",
    "* I am doing Part B of this lab by myself and I don't have a partner.\n",
    "* My partner for Part B of this lab is [NAME] with email [berkeley.edu email address]. [NAME] will submit for both of us on Gradescope.\n",
    "\n",
    "Please copy and paste **ONE** of above statements and fill in blanks if needed. If you work with a partner, make sure only one of you submit on Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 4. Poisson $(1)$ Approximation to Binomial Distributions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Roughly stated, a theorem we proved in class says that if $n$ is large and $p$ is small, then the binomial $(n, p)$ probabilities are close to Poisson $(np)$ probabilities. \n",
    "\n",
    "Therefore if $n$ is large then the binomial $(n, 1/n)$ probabilities should be close to Poisson $(1)$ probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 4a) [CODE] Binomial $(10, 1/10)$ Distribution ###\n",
    "If `values` is an array of integers in the range 0 through $n$, then\n",
    "\n",
    "`stats.binom.pmf(values, n, p)`\n",
    "\n",
    "evaluates to an array of the binomial $(n, p)$ probabilities of the entries in `values`.\n",
    "\n",
    "Display a histogram of the binomial $(10, 1/10)$ distribution. Notice how the probabilities are concentrated on the low values. This is a signal to start thinking about Poisson approximations, even though the number of trials ($n = 10$) isn't very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "# binomial (n, 1/n) distribution\n",
    "n = 10                             # number of trials\n",
    "\n",
    "k = ...                            # possible values\n",
    "binom_probs = ...                  # binomial (n, 1/n) probabilities\n",
    "\n",
    "\n",
    "binom_dist = ...\n",
    "\n",
    "Plot(binom_dist)\n",
    "plt.title('Binomial (10, 1/10) Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Since $n = 10$ isn't very large, this distribution doesn't look exactly like the Poisson $(1)$ distribution though the two have many similarities. Run the cell below to see the overlaid histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "poisson_1_probs = stats.poisson.pmf(k, 1)\n",
    "poisson_1_dist = Table().values(k).probabilities(poisson_1_probs)\n",
    "\n",
    "Plots('Binomial (10, 1/10)', binom_dist, 'Poisson (1)', poisson_1_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "At this point it will come as no surprise that the Poisson $(1)$ approximation gets better as $n$ increases. You will quantify this in the remaining exercises below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 4b) [CODE] TVD between the Binomial $(n, 1/n)$ Distribution and its Poisson Approximation ###\n",
    "Define a function `binomial_Poisson_tvd` that takes $n$ as its argument and returns the total variation distance between the binomial $(n, 1/n)$ and Poisson $(1)$ distributions. As before, it's fine to compute the Poisson $(1)$ probabilities only on 0 through $n$, the possible values of the binomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "def binomial_Poisson_tvd(n):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "As a check to see if your function is working correctly, run the cell below. The output should be about $1$%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "binomial_Poisson_tvd(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Fill in the blank with the name of a distribution and its numerical parameter or parameters.\n",
    "\n",
    "The output of the code cell above is the biggest possible error in using the Poisson $(1)$ distribution to approximate the $\\underline{~~~~~~~~~~~~~~~~}$ distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 4c) [CODE] Error in Approximation ###\n",
    "Extend `tvd_table` defined earlier with a column labeled `'Binomial (n, 1/n)'` that contains the TVD between the binomial $(n, 1/n)$ and Poisson $(1)$ distributions, where in each row $n$ is given by the entry in Column 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "binom_tvds = tvd_table...\n",
    "\n",
    "tvd_table = tvd_table...\n",
    "\n",
    "tvd_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Run the cell below to get overlaid line plots of the two TVD columns as functions of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "tvd_table.plot(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "The graph of the binomial-Poisson TVDs drops sharply, though not as sharply as the matches-Poisson TVD graph. \n",
    "\n",
    "Fill in the blanks (use the code cell below if you need to):\n",
    "\n",
    "For values of $n$ that are about $\\underline{~~~~~~~~~~~~~~~~}$ or more, Poisson $(1)$ approximations to binomial $(n, 1/n)$ probabilities will be off by at most 0.5%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Now you can use total variation distance to help answer the question, \"How large does $n$ have to be before I can use the Poisson $(1)$ approximation to the binomial $(n, 1/n)$ distribution?\" \n",
    "\n",
    "- First decide how much error you are prepared to tolerate in your approximations. \n",
    "- Then use `tvd_table` (or an extended one with larger values of $n$) to find the smallest $n$ for which the TVD is below your threshold error. \n",
    "- For that $n$ or larger, the error in your Poisson $(1)$ probability approximations will be below your threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 5: A Simple Bound for the TVD ###\n",
    "\n",
    "You have calculated the TVD by calculating both the exact binomial and the approximate Poisson probabilities, and you have seen that the TVD is small for large $n$.\n",
    "\n",
    "But what's the point of approximations and TVD if we have to compute the exact binomial probabilities to get the TVD in the first place?\n",
    "\n",
    "In fact there is no point in approximation if you can just find the exact chance. But for large enough $n$, the exact computations become infeasible. So probabilists have worked out simple mathematical upper bounds on the TVD between the Poisson and binomial (or binomial-like) distributions. The fundamental work in this area was by the late [Prof. Lucien LeCam](https://en.wikipedia.org/wiki/Lucien_Le_Cam) of the Statistics department at Berkeley.\n",
    "\n",
    "### 5a) [Written] The Poisson-Binomial Distribution and LeCam's Theorem ###\n",
    "\n",
    "Read the statement of [LeCam's Theorem](https://en.wikipedia.org/wiki/Le_Cam%27s_theorem). It is about the Poisson approximation to the *Poisson-binomial* distribution. That's the distribution of the sum of independent indicators that need not be identically distributed.\n",
    "\n",
    "- First explain why the binomial distribution is a special case of the Poisson-binomial distribution.\n",
    "\n",
    "- Then figure out how LeCam's theorem applies to the approximation you are studying in this lab, and hence find LeCam's upper bound on the TVD between the binomial $(n, 1/n)$ distribution and its Poisson $(1)$ approximation.\n",
    "\n",
    "You just have to apply the theorem carefully. Think about what the $p_i$'s have to be, and be careful about factors of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 5b) Confirming the Upper Bound ###\n",
    "The proof of LeCam's theorem is beyond the scope of this course. But you can check that the theorem does indeed give an upper bound, by drawing overlaid plots of the TVD and the bound.\n",
    "\n",
    "Complete the cell below to augment `tvd_table` with a column `\"LeCam's Bound\"` that contains the bound you found in **a**, and draw the overlaid plots. \n",
    "\n",
    "The limits on the vertical axis have been chosen for comparability with the plot in Part **4c**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tvd_table = tvd_table.with_columns(\n",
    "    \"LeCam's Bound\", ...\n",
    ")\n",
    "\n",
    "tvd_table.plot(0)\n",
    "plt.ylim(0, 0.06);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 5c) Using the Bound ###\n",
    "\n",
    "Fill in the blank **without calculation**. \n",
    "\n",
    "If you use the Poisson $(1)$ distribution to approximate binomial $(1000, 1/1000)$ probabilities, the worst error you can make is no more than $\\underline{~~~~~~~~~~~~~~~~~~~~}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 6: Biggest Possible Error ##\n",
    "\n",
    "To conclude the lab, you are going to prove that the TVD can be interpreted as a maximum difference of probabilities.\n",
    "\n",
    "We are going to compare two probability distributions $P_{blue}$ and $P_{gold}$ on a finite set of values $S$. Suppose the values are labeled $1, 2, \\ldots, n$. \n",
    "\n",
    "The *total variation distance between $P_{blue}$ and $P_{gold}$* is defined as\n",
    "\n",
    "$$\n",
    "\\| P_{blue} - P_{gold}\\|_{TVD} ~ = ~\n",
    "\\max\\{ \\lvert P_{blue}(A) - P_{gold}(A) \\rvert : A \\subseteq S\\}\n",
    "$$\n",
    "\n",
    "The definition says: For every event $A$, compute how far off $P_{blue}(A)$ is from $P_{gold}(A)$. The TVD is the biggest value among all these differences.\n",
    "\n",
    "That doesn't look at all like what we have been calculating as the TVD starting way back in Data 8. But in fact it's the same thing. It's your job to show how. \n",
    "\n",
    "Before you get started, confirm your understanding of the definition. Suppose you calculate the TVD between two distributions and get 0.003. That says that if you list all possible events and compare their probabilities under the two distributions, the biggest difference you will get is 3/1000. The two distributions are pretty close. \n",
    "\n",
    "The goal of this part of the lab is to show that this new definition of TVD is equivalent to the calculation we have been doing all along. Let's start by setting up some notation. For each $i$ in $S$, let $P_{blue}(i) = b_i$ and let $P_{gold}(i) = g_i$. If you imagine a bar graph or histogram of each distribution, then $b_i$ is the area of the blue bar at the value $i$, and $g_i$ is the area of the gold bar at $i$.\n",
    "\n",
    "In this notation, our familiar calculation of the TVD is\n",
    "\n",
    "$$\n",
    "\\frac{1}{2} \\sum_{i \\in S} \\lvert b_i - g_i \\rvert\n",
    "$$\n",
    "\n",
    "In this question and the next you will show that \n",
    "\n",
    "$$\n",
    "\\max\\{ \\lvert P_{blue}(A) - P_{gold}(A) \\rvert : A \\subseteq S\\} ~ = ~ \n",
    "\\frac{1}{2} \\sum_{i \\in S} \\lvert b_i - g_i \\rvert\n",
    "$$\n",
    "\n",
    "Three events will be important in the calculations.\n",
    "\n",
    "The set of values for which the blue bars exceed the gold:\n",
    "$$\n",
    "B = \\{i: b_i > g_i\\}\n",
    "$$\n",
    "\n",
    "The set of values for which the gold bars exceed the blue:\n",
    "$$\n",
    "G = \\{i: g_i > b_i\\}\n",
    "$$\n",
    "\n",
    "The set of values for which the blue bars and gold bars are equal:\n",
    "$$\n",
    "E = \\{i: b_i = g_i\\}\n",
    "$$\n",
    "\n",
    "Keep in mind that for any event $A$,\n",
    "$$\n",
    "P_{blue}(A) = \\sum_{i \\in A} b_i ~~~~~~~ \\text{and} ~~~~~~~\n",
    "P_{gold}(A) = \\sum_{i \\in A} g_i\n",
    "$$\n",
    "\n",
    "### This part of the lab is entirely written. There is no code. ###\n",
    "\n",
    "### 6a) ###\n",
    "Find the value of\n",
    "$$\n",
    "\\sum_{i \\in B} b_i ~ + ~ \n",
    "\\sum_{i \\in G} b_i ~ + ~ \n",
    "\\sum_{i \\in E} b_i \n",
    "$$\n",
    "\n",
    "Repeat the calculation after replacing $b_i$ by $g_i$ in all three sums above.\n",
    "\n",
    "Hence show that\n",
    "$$\n",
    "\\sum_{i \\in B} (b_i - g_i) ~ = ~ \\sum_{i \\in G} (g_i - b_i)\n",
    "$$\n",
    "\n",
    "This proves a statement we have made in Data 8 and in Part **1a** of this lab: \"The amount by which the blue bars exceed the gold is the same as the amount by which the gold bars exceed the blue.\" \n",
    "\n",
    "### 6b) ###\n",
    "Our usual calculation of TVD is\n",
    "$$\n",
    "\\frac{1}{2} \\sum_{i \\in S} \\lvert b_i - g_i \\rvert\n",
    "$$\n",
    "\n",
    "Partition the sum into two pieces to show that\n",
    "\n",
    "$$\n",
    "\\frac{1}{2} \\sum_{i \\in S} \\lvert b_i - g_i \\rvert ~ = ~\n",
    "\\sum_{i \\in B} (b_i - g_i) ~ = ~ \\sum_{i \\in G} (g_i - b_i)\n",
    "$$\n",
    "\n",
    "This proves another statement we made in Data 8 and Part **1a** of this lab: \"The TVD is the amount by which the blue bars exceed the gold.\"\n",
    "\n",
    "### 6c) ###\n",
    "Now let $A$ be any event. Show that \n",
    "$$\n",
    "P_{blue}(A) - P_{gold}(A) ~ = ~ \n",
    "\\sum_{i \\in AB} (b_i - g_i) ~ - ~ \\sum_{i \\in AG} (g_i - b_i)\n",
    "$$\n",
    "\n",
    "Hence show that\n",
    "$$\n",
    "P_{blue}(A) - P_{gold}(A) ~ \\le ~ \n",
    "\\sum_{i \\in AB} (b_i - g_i) ~~~~~~ \\text{and} ~~~~~~\n",
    "P_{gold}(A) - P_{blue}(A) ~ \\le ~ \n",
    "\\sum_{i \\in AG} (g_i - b_i)\n",
    "$$\n",
    "\n",
    "### 6d) ###\n",
    "Use the first of the two inequalities in **c** to show that if $P_{blue}(A) - P_{gold}(A) > 0$ then\n",
    "\n",
    "$$\n",
    "\\lvert P_{blue}(A) - P_{gold}(A) \\rvert ~ \\le ~ \\sum_{i \\in B} (b_i - g_i)\n",
    "$$\n",
    "\n",
    "Use the second of the two inequalities in **c** to show that if $P_{blue}(A) - P_{gold}(A) < 0$ then\n",
    "\n",
    "$$\n",
    "\\lvert P_{blue}(A) - P_{gold}(A) \\rvert ~ \\le ~ \\sum_{i \\in G} (g_i - b_i)\n",
    "$$\n",
    "\n",
    "### 6e) ###\n",
    "Identify an event for which one of the inequalities in **d** is an equality.\n",
    "\n",
    "Explain why you now have a complete proof of\n",
    "\n",
    "$$\n",
    "\\max\\{ \\lvert P_{blue}(A) - P_{gold}(A) \\rvert : A \\subseteq S\\} ~ = ~ \n",
    "\\frac{1}{2} \\sum_{i \\in S} \\lvert b_i - g_i \\rvert\n",
    "$$\n",
    "\n",
    "That is, our usual calculation of the TVD is equivalent to finding the biggest difference between probabilities assigned by the two distributions to any event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "# Part B of the lab ends here, and is due by 11:59 pm Monday February 7 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Conclusion ##\n",
    "What you have learned in this lab:\n",
    "- Let $X$ be a discrete random variable. If you use an approximation to the distribution of $X$, then the total variation distance between the exact and approximate distributions measures the worst error you can make in approximating probabilities of events determined by $X$. \n",
    "- Many random variables in this lab have a large number of possible values, and the approximating Poisson distribution has infinitely many possible values. But no matter how large $n$ is, the *probable* values of all the variables are in a very small range â€” 0 through about 8 or 10 â€” because all of the distributions are roughly Poisson $(1)$.\n",
    "- The total variation distance between the distribution of the number of matches in a random permutation of $n$ elements and its Poisson $(1)$ approximation falls very sharply. By about 10 elements or so, you might as well use the Poisson distribution for the number of matches.\n",
    "- The total variation distance between the binomial $(n, 1/n)$ and Poisson $(1)$ distributions falls sharply as a function of $n$ and is below 1% even for moderate values of $n$.\n",
    "- There is a simple upper bound for this total variation distance and hence for the worst error of approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Submission Instructions ##\n",
    "\n",
    "Many assignments throughout the course will have a written portion and a code portion. Please follow the directions below to properly submit both portions.\n",
    "\n",
    "### Written Portion ###\n",
    "*  Scan all the pages into a PDF. You can use any scanner or a phone using applications such as CamScanner. Please **DO NOT** simply take pictures using your phone. \n",
    "* Please start a new page for each question. If you have already written multiple questions on the same page, you can crop the image in CamScanner or fold your page over (the old-fashioned way). This helps expedite grading.\n",
    "* It is your responsibility to check that all the work on all the scanned pages is legible.\n",
    "\n",
    "### Code Portion ###\n",
    "* Save your notebook using File > Save and Checkpoint.\n",
    "* Generate a PDF file using File > Download as > PDF via LaTeX. This might take a few seconds and will automatically download a PDF version of this notebook.\n",
    "    * If you have issues, please make a follow-up post on the general Lab 1 Ed thread.\n",
    "    \n",
    "### Submitting ###\n",
    "* Combine the PDFs from the written and code portions into one PDF.  [Here](https://smallpdf.com/merge-pdf) is a useful tool for doing so. \n",
    "* Submit the assignment to Lab 1 on Gradescope. \n",
    "* **Make sure to assign each page of your pdf to the correct question.**\n",
    "* **It is your responsibility to verify that all of your work shows up in your final PDF submission.**\n",
    "\n",
    "If you have questions about scanning or uploading your work, please post a follow-up to the [Ed thread](https://edstem.org/us/courses/17989/discussion/1027297) on this topic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## **We will not grade assignments which do not have pages selected for each question.** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "checksums": [
   "b37a61c4040ae61458ee19c79e9305a7",
   "9c78703d0d09b2932d35ae75053a5129",
   "518c84f8a1f148dbd174743a2ce02a06",
   "1111761b43a695390b8e8794765e7f05",
   "bbbd0bf658428e10cbfd889247879924",
   "137ad08e81e4f62848e32f91454444a1",
   "0ff5ab8a705249631f781ac08494bdaa",
   "036db2d2d84687f1befca7d08aa364f8",
   "e5da377a66787f440cf2eef7f03b0390",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "640061103a186fd26f59746dd4d6de57",
   "215ed6c8654224bcdb429ca58d5e7135",
   "4fb206b23cca8f1941265599b0f0f320",
   "3c7292e1d847529b3abb46265ab6a10f",
   "b182444b425e530aebac0b1429b8d999",
   "c58db66b6fee81063dd7637932e6e637",
   "8d31345e276966579a2701d3c436204e",
   "dc8bbeae78e29542dbc5821cbfe3e544",
   "05b6c4f7180c1a2613cba1b9916e62c6",
   "ca211c8d334df1876ebb8c81418793a5",
   "030e13d9e6c724ea6ece121d929cd63b",
   "640061103a186fd26f59746dd4d6de57",
   "bab63f4108dc2dba9026d81ac98f6bcf",
   "9c86dc37d04d887fa0f5783fecacd9d7",
   "b9c4afd0d6308b642b09aa30c7aac726",
   "61eabfbb6c12528de4cb52a76fa50a81",
   "1c9082e82d8238d32d369f3533ca5e8c",
   "1dfb51cb71d2f70285237eea8507884f",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "bf1f7cacc1f8f52a58a3967f91a19f66",
   "b9b9cba3588e3769333618b5f4f304d6",
   "ef6ffe53b34e7f709afb7097e7911b96",
   "67103cc9f45ab2bad10bf4cc85d65d19",
   "07e8aa5e3271f9eeabea10bf1d87d8fd",
   "25df0da9d04ff98129e0a93242a87af4",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "1aabb21d7cc08586d33f6f3562958996",
   "341062640dfbd339294b11cd1448f3d4",
   "640061103a186fd26f59746dd4d6de57",
   "42083454535fdc3249d3e08b7701b322",
   "6891bcdabd7c4df54746baf6abb748c5",
   "17c82d80cd605f89249c1a4dcaa6cf5d",
   "ccd968724b42bfca21602c4b01fe670e",
   "a69f522a6aaff30f0c94bb6718e0f0a6",
   "ebe5b742470b60a4776142e086c97581",
   "4f5c213244734ff87eb69f271c057e53",
   "ef5759ff92165c4e90015fe67846ec3b",
   "097e0986d8b306e495a9be667cdabc71",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "b0f66f48ec744bdf5328aa5b336ca88c",
   "07f2b0a9b704a628743082e0968f5cbc",
   "0e12e19d762c8dedc68e6fad4c7b802d",
   "2f43b42fd833d1e77420a8dae7419000",
   "b29e5ac6a193793001fa157625e88b9e",
   "0ac6e1505530a756a34808a362a2b6a9",
   "0f9693248cdcf99ce169c189f0d93a61",
   "6ffc1f0498e2ef6453f3176c7c457fab",
   "7b90ee6f8781d1bc4123617b145c4368",
   "ca96bc1cd3c401d2a854d2a19c3e4922",
   "640061103a186fd26f59746dd4d6de57",
   "d01367822725fa07d86c3b43d29b31d3",
   "1901b006935012cba106a07b36d0d89e",
   "c76dea0c87800f230281b5d5e741dbcf",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "640061103a186fd26f59746dd4d6de57",
   "e35b43c56e720a142f61a1a3da176c96",
   "fc870e7d454dd6c24a25242fbbf97b3b",
   "78f47abb6597e3867c7abb5f59abb8b0",
   "c1998857407a30636b74dd83e9fd99b7",
   "1ba5798afe8b4b9b50a92451638e4938",
   "6019af823cc745ff239519a0110097ed",
   "30115b9210703022991b1b6ea563b523",
   "7974463748638706c4ccb40ee8e0717b",
   "71f2f1609b5cc73741f9e07b05ab0e6c",
   "732477c7f5d4080670738ff6df6da214",
   "44fd51da968ba3e9826a7bfc01c5315b",
   "1f49d9af84494ee05ddee8bfb0340f27",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "a5c83e9c609c7ba7ea08197f3a40884f",
   "9f510c9287290ff2ae0ca220016f6f7a",
   "a44fc18c480b10ed64ec11d21b2b3d43",
   "2e2c2c4d314a75eb8b8ef2bc1765ecac",
   "406b98dcbaa39ff2691d337b1e491fba",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "2f43b42fd833d1e77420a8dae7419000",
   "7d03d983dcfc893b98847e1b9516b925",
   "80a9faa8a0c9365d1002e77c24a55632",
   "c33657e62a9a68c61800d0a3f7b154ab",
   "90d2492e6af7a7fa061f94b6f2806a82",
   "a5dd55f02ec68c39ef5af1d8a61002cd",
   "0de20b93bb878d597e59213991465648",
   "640061103a186fd26f59746dd4d6de57",
   "593245b0a8f85d00702a6218fec2f002",
   "9897ca5ed55443eabbbc415a3abff769",
   "640061103a186fd26f59746dd4d6de57",
   "658fea8fb6d1379c0da9f8954a3602f2",
   "c380de24e809ea0cb67defd961149c4c",
   "28b84f784840e42a5b8327aab8f973c0",
   "d41d8cd98f00b204e9800998ecf8427e"
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "number_of_pagebreaks": 7,
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
